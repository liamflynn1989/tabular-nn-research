{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAIRO: Robust Regression via Rank-then-Calibrate\n",
    "\n",
    "This tutorial explains **CAIRO** (Calibrate After Initial Rank Ordering), a two-stage regression framework that is robust to outliers and heavy-tailed noise.\n",
    "\n",
    "**Paper:** [arXiv:2602.14440](https://arxiv.org/abs/2602.14440)\n",
    "\n",
    "## Why CAIRO?\n",
    "\n",
    "Standard regression methods (MSE) have a fundamental problem: they **conflate learning ordering with learning scale**.\n",
    "\n",
    "- **Ordering:** Which examples have higher/lower values?\n",
    "- **Scale:** What are the actual numerical values?\n",
    "\n",
    "When you have outliers or heavy-tailed distributions, MSE loss is dominated by extreme values. A single outlier can dramatically shift your model's predictions.\n",
    "\n",
    "**CAIRO's key insight:** Learn ordering first (which is scale-invariant), then recover scale separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import CAIRO, create_cairo\n",
    "from models.base import MLP\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Two-Stage Framework\n",
    "\n",
    "### Stage 1: Learn Ranking via Scale-Invariant Loss\n",
    "\n",
    "Instead of minimizing MSE, we minimize a **pairwise ranking loss**:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{rank}} = \\sum_{i,j: y_i > y_j} w_{ij} \\cdot \\log(1 + e^{-\\sigma(s_i - s_j)})$$\n",
    "\n",
    "Where:\n",
    "- $s_i = g(x_i)$ is the score for example $i$\n",
    "- $w_{ij}$ is a weight (uniform for Kendall's τ, $|y_i - y_j|$ for Gini)\n",
    "- $\\sigma$ controls the sigmoid steepness\n",
    "\n",
    "This loss penalizes misordered pairs: when $y_i > y_j$ but $s_i < s_j$.\n",
    "\n",
    "**Why is this robust?** The log-sigmoid saturates for large score differences, so outliers can't dominate the gradient.\n",
    "\n",
    "### Stage 2: Recover Scale via Isotonic Regression\n",
    "\n",
    "After learning a scoring function $g(x)$ that correctly orders examples, we fit a **monotone increasing function** to map scores back to target values:\n",
    "\n",
    "$$f^* = \\arg\\min_{f \\in \\mathcal{F}} \\sum_i (y_i - f(g(x_i)))^2$$\n",
    "\n",
    "Where $\\mathcal{F}$ is the set of non-decreasing functions.\n",
    "\n",
    "This is solved by **isotonic regression** (Pool Adjacent Violators Algorithm), which is:\n",
    "- Non-parametric (no assumptions about the mapping)\n",
    "- Efficient: O(n) on sorted data\n",
    "- Guaranteed to preserve the ordering from Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Synthetic Data with Heavy Tails\n",
    "\n",
    "Let's create data where CAIRO shines: heavy-tailed noise with outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heavy_tailed_data(n_samples=1000, n_features=10, noise_type='lognormal'):\n",
    "    \"\"\"\n",
    "    Generate regression data with heavy-tailed noise.\n",
    "    \n",
    "    noise_type:\n",
    "    - 'gaussian': Standard normal noise (for comparison)\n",
    "    - 'lognormal': Heavy-tailed multiplicative noise\n",
    "    - 'outliers': Gaussian with 10% outliers\n",
    "    \"\"\"\n",
    "    # Features\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # True signal: linear with interaction\n",
    "    weights = np.random.randn(n_features)\n",
    "    signal = X @ weights / np.sqrt(n_features)\n",
    "    \n",
    "    # Apply noise\n",
    "    if noise_type == 'gaussian':\n",
    "        noise = np.random.randn(n_samples)\n",
    "        y = signal + noise\n",
    "    elif noise_type == 'lognormal':\n",
    "        # Heteroskedastic, heavy-tailed noise\n",
    "        mu = np.exp(signal)  # Mean depends on signal\n",
    "        noise = np.random.lognormal(0, 1, n_samples) - 1  # Zero-mean lognormal\n",
    "        y = mu + noise * np.sqrt(mu)  # Variance scales with mean\n",
    "    elif noise_type == 'outliers':\n",
    "        noise = np.random.randn(n_samples)\n",
    "        # Add outliers: 10% of points have 10x noise\n",
    "        outlier_mask = np.random.rand(n_samples) < 0.1\n",
    "        noise[outlier_mask] *= 10\n",
    "        y = signal + noise\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown noise_type: {noise_type}\")\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(X, dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32),\n",
    "        signal\n",
    "    )\n",
    "\n",
    "# Generate different noise regimes\n",
    "X_gaussian, y_gaussian, signal_gaussian = generate_heavy_tailed_data(noise_type='gaussian')\n",
    "X_lognormal, y_lognormal, signal_lognormal = generate_heavy_tailed_data(noise_type='lognormal')\n",
    "X_outliers, y_outliers, signal_outliers = generate_heavy_tailed_data(noise_type='outliers')\n",
    "\n",
    "# Visualize the distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(y_gaussian.numpy(), bins=50, alpha=0.7)\n",
    "axes[0].set_title('Gaussian Noise')\n",
    "axes[0].set_xlabel('Target Value')\n",
    "\n",
    "axes[1].hist(y_lognormal.numpy(), bins=50, alpha=0.7)\n",
    "axes[1].set_title('Lognormal (Heavy-Tailed) Noise')\n",
    "axes[1].set_xlabel('Target Value')\n",
    "\n",
    "axes[2].hist(y_outliers.numpy(), bins=50, alpha=0.7)\n",
    "axes[2].set_title('Gaussian + 10% Outliers')\n",
    "axes[2].set_xlabel('Target Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Ranking Losses\n",
    "\n",
    "CAIRO supports three ranking loss variants:\n",
    "\n",
    "### 1. RankNet (Uniform Weights)\n",
    "Optimizes **Kendall's τ** - treats all misordered pairs equally.\n",
    "\n",
    "### 2. RankNet-GiniW (Absolute Gap Weights)\n",
    "Optimizes **Gini covariance** - weights pairs by $|y_i - y_j|$, so large gaps matter more.\n",
    "\n",
    "### 3. GiniNet-SoftRank (Pointwise)\n",
    "Uses differentiable soft ranks - O(n log n) complexity vs O(n²) for pairwise.\n",
    "\n",
    "Let's visualize how the log-sigmoid loss provides robustness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MSE vs RankNet loss gradients\n",
    "score_diff = np.linspace(-5, 5, 100)\n",
    "\n",
    "# MSE gradient (for a single pair): 2 * (y_i - y_j) - 2 * (s_i - s_j)\n",
    "# Simplified: gradient w.r.t. score_diff when y_i > y_j\n",
    "mse_gradient = -2 * np.ones_like(score_diff)  # Constant gradient\n",
    "\n",
    "# RankNet gradient: sigmoid(-score_diff) when y_i > y_j\n",
    "sigma = 1.0\n",
    "ranknet_gradient = -1 / (1 + np.exp(sigma * score_diff))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(score_diff, np.abs(mse_gradient), 'b-', linewidth=2, label='MSE Loss (constant)')\n",
    "ax.plot(score_diff, np.abs(ranknet_gradient), 'r-', linewidth=2, label='RankNet Loss')\n",
    "\n",
    "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.fill_between(score_diff, 0, np.abs(ranknet_gradient), alpha=0.3, color='red')\n",
    "\n",
    "ax.set_xlabel('Score Difference (s_i - s_j)', fontsize=12)\n",
    "ax.set_ylabel('|Gradient|', fontsize=12)\n",
    "ax.set_title('Gradient Magnitude: RankNet saturates, MSE does not', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 2.5)\n",
    "\n",
    "ax.annotate('RankNet saturates:\\nno big gradient from\\nalready-correct pairs',\n",
    "            xy=(3, 0.1), fontsize=10, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CAIRO\n",
    "\n",
    "Let's train CAIRO and compare it to a standard MLP on heavy-tailed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def train_cairo(X, y, n_epochs=100, lr=0.01):\n",
    "    \"\"\"Train CAIRO model.\"\"\"\n",
    "    model = CAIRO(\n",
    "        d_in=X.shape[1],\n",
    "        d_out=1,\n",
    "        n_blocks=2,\n",
    "        d_block=64,\n",
    "        loss_type=\"ranknet\",\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        scores = model.get_scores(X)\n",
    "        loss = model.compute_ranking_loss(scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Stage 2: Fit calibrator\n",
    "    model.fit_calibrator(X, y)\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "def train_mlp(X, y, n_epochs=100, lr=0.01):\n",
    "    \"\"\"Train standard MLP with MSE.\"\"\"\n",
    "    model = MLP(\n",
    "        d_in=X.shape[1],\n",
    "        d_out=1,\n",
    "        n_blocks=2,\n",
    "        d_block=64,\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y.unsqueeze(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "def evaluate_model(model, X, y, is_cairo=False):\n",
    "    \"\"\"Evaluate model on RMSE and ranking metrics.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X).squeeze()\n",
    "    \n",
    "    rmse = torch.sqrt(((pred - y) ** 2).mean()).item()\n",
    "    \n",
    "    # Ranking metrics\n",
    "    tau, _ = kendalltau(pred.numpy(), y.numpy())\n",
    "    rho, _ = spearmanr(pred.numpy(), y.numpy())\n",
    "    \n",
    "    return {'rmse': rmse, 'kendall_tau': tau, 'spearman_rho': rho}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on heavy-tailed data\n",
    "print(\"Training on Lognormal (heavy-tailed) data...\")\n",
    "cairo_model, cairo_losses = train_cairo(X_lognormal, y_lognormal)\n",
    "mlp_model, mlp_losses = train_mlp(X_lognormal, y_lognormal)\n",
    "\n",
    "# Evaluate\n",
    "cairo_metrics = evaluate_model(cairo_model, X_lognormal, y_lognormal, is_cairo=True)\n",
    "mlp_metrics = evaluate_model(mlp_model, X_lognormal, y_lognormal)\n",
    "\n",
    "print(f\"\\nCAIRO - RMSE: {cairo_metrics['rmse']:.4f}, Kendall's τ: {cairo_metrics['kendall_tau']:.4f}\")\n",
    "print(f\"MLP   - RMSE: {mlp_metrics['rmse']:.4f}, Kendall's τ: {mlp_metrics['kendall_tau']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare across noise regimes\n",
    "results = {}\n",
    "\n",
    "for name, (X, y) in [\n",
    "    ('Gaussian', (X_gaussian, y_gaussian)),\n",
    "    ('Lognormal', (X_lognormal, y_lognormal)),\n",
    "    ('Outliers', (X_outliers, y_outliers)),\n",
    "]:\n",
    "    print(f\"\\n=== {name} Noise ===\")\n",
    "    \n",
    "    cairo_m, _ = train_cairo(X, y)\n",
    "    mlp_m, _ = train_mlp(X, y)\n",
    "    \n",
    "    cairo_res = evaluate_model(cairo_m, X, y, is_cairo=True)\n",
    "    mlp_res = evaluate_model(mlp_m, X, y)\n",
    "    \n",
    "    results[name] = {'CAIRO': cairo_res, 'MLP': mlp_res}\n",
    "    \n",
    "    print(f\"  CAIRO - RMSE: {cairo_res['rmse']:.4f}, τ: {cairo_res['kendall_tau']:.4f}\")\n",
    "    print(f\"  MLP   - RMSE: {mlp_res['rmse']:.4f}, τ: {mlp_res['kendall_tau']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "noise_types = list(results.keys())\n",
    "cairo_rmse = [results[n]['CAIRO']['rmse'] for n in noise_types]\n",
    "mlp_rmse = [results[n]['MLP']['rmse'] for n in noise_types]\n",
    "\n",
    "x = np.arange(len(noise_types))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, mlp_rmse, width, label='MLP (MSE)', color='blue', alpha=0.7)\n",
    "axes[0].bar(x + width/2, cairo_rmse, width, label='CAIRO', color='red', alpha=0.7)\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('RMSE by Noise Type')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(noise_types)\n",
    "axes[0].legend()\n",
    "\n",
    "# Kendall's tau comparison\n",
    "cairo_tau = [results[n]['CAIRO']['kendall_tau'] for n in noise_types]\n",
    "mlp_tau = [results[n]['MLP']['kendall_tau'] for n in noise_types]\n",
    "\n",
    "axes[1].bar(x - width/2, mlp_tau, width, label='MLP (MSE)', color='blue', alpha=0.7)\n",
    "axes[1].bar(x + width/2, cairo_tau, width, label='CAIRO', color='red', alpha=0.7)\n",
    "axes[1].set_ylabel(\"Kendall's τ\")\n",
    "axes[1].set_title('Ranking Accuracy by Noise Type')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(noise_types)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Two Stages\n",
    "\n",
    "Let's see what Stage 1 (ranking) and Stage 2 (calibration) each contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a CAIRO model and examine stages\n",
    "cairo_demo, _ = train_cairo(X_lognormal, y_lognormal)\n",
    "\n",
    "# Get Stage 1 scores (before calibration)\n",
    "cairo_demo.eval()\n",
    "with torch.no_grad():\n",
    "    scores = cairo_demo.get_scores(X_lognormal).numpy()\n",
    "\n",
    "# Get Stage 2 calibrated predictions\n",
    "predictions = cairo_demo(X_lognormal).squeeze().numpy()\n",
    "targets = y_lognormal.numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Stage 1: Scores vs Targets\n",
    "axes[0].scatter(targets, scores, alpha=0.5, s=10)\n",
    "axes[0].set_xlabel('True Target')\n",
    "axes[0].set_ylabel('Stage 1 Score')\n",
    "axes[0].set_title('Stage 1: Scores preserve ordering\\n(not on target scale)')\n",
    "\n",
    "# Stage 2 calibration function\n",
    "# Sort by scores to show the isotonic function\n",
    "sort_idx = np.argsort(scores)\n",
    "axes[1].scatter(scores[sort_idx], targets[sort_idx], alpha=0.3, s=10, label='Data')\n",
    "axes[1].plot(scores[sort_idx], predictions[sort_idx], 'r-', linewidth=2, label='Isotonic fit')\n",
    "axes[1].set_xlabel('Stage 1 Score')\n",
    "axes[1].set_ylabel('Target / Prediction')\n",
    "axes[1].set_title('Stage 2: Isotonic regression\\nmaps scores to target scale')\n",
    "axes[1].legend()\n",
    "\n",
    "# Final predictions vs true\n",
    "axes[2].scatter(targets, predictions, alpha=0.5, s=10)\n",
    "axes[2].plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', linewidth=2)\n",
    "axes[2].set_xlabel('True Target')\n",
    "axes[2].set_ylabel('CAIRO Prediction')\n",
    "axes[2].set_title('Final Predictions\\n(after calibration)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **CAIRO excels with heavy-tailed noise**: When your data has outliers or fat tails, CAIRO's ranking loss is more robust than MSE.\n",
    "\n",
    "2. **Ranking vs Scale**: The two-stage approach separates concerns - first get the ordering right, then recover scale.\n",
    "\n",
    "3. **Log-sigmoid saturation**: The pairwise loss saturates for large errors, naturally limiting outlier influence.\n",
    "\n",
    "4. **Use cases**:\n",
    "   - Financial data (fat-tailed returns)\n",
    "   - Heteroskedastic targets (variance changes with level)\n",
    "   - Data with measurement outliers\n",
    "   - When ranking matters more than exact values\n",
    "\n",
    "5. **Trade-offs**:\n",
    "   - On clean Gaussian data, MSE may be slightly better\n",
    "   - O(n²) complexity for pairwise losses (use softrank for large batches)\n",
    "   - Requires two-stage training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
